{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c161710-fc66-426f-8c96-28440b9c9626",
   "metadata": {},
   "source": [
    "# Reasoning without Observation\n",
    "\n",
    "In [ReWOO](https://arxiv.org/abs/2305.18323), Xu, et. al, propose an agent that combines a multi-step planner and variable substitution for effective tool use. It was designed to improve on the ReACT-style agent architecture in the following ways:\n",
    "\n",
    "1. Reduce token consumption and execution time by generating the full chain of tools used in a single pass. (_ReACT-style agent architecture requires many LLM calls with redundant prefixes (since the system prompt and previous steps are provided to the LLM for each reasoning step_)\n",
    "2. Simplify the fine-tuning process. Since the planning data doesn't depend on the outputs of the tool, models can be fine-tuned without actually invoking the tools (in theory).\n",
    "\n",
    "\n",
    "The following diagram outlines ReWOO's overall computation graph:\n",
    "\n",
    "![ReWoo Diagram](./img/rewoo.png)\n",
    "\n",
    "ReWOO is made of 3 modules:\n",
    "\n",
    "1. ðŸ§ **Planner**: Generate the plan in the following format:\n",
    "```text\n",
    "Plan: <reasoning>\n",
    "#E1 = Tool[argument for tool]\n",
    "Plan: <reasoning>\n",
    "#E2 = Tool[argument for tool with #E1 variable substitution]\n",
    "...\n",
    "```\n",
    "3. **Worker**: executes the tool with the provided arguments.\n",
    "4. ðŸ§ **Solver**: generates the answer for the initial task based on the tool observations.\n",
    "\n",
    "The modules with a ðŸ§  emoji depend on an LLM call. Notice that we avoid redundant calls to the planner LLM by using variable substitution.\n",
    "\n",
    "In this example, each module is represented by a LangGraph node. The end result will leave a trace that looks [like this one](https://smith.langchain.com/public/39dbdcf8-fbcc-4479-8e28-15377ca5e653/r). Let's get started!\n",
    "\n",
    "## 0. Prerequisites\n",
    "\n",
    "For this example, we will provide the agent with a Tavily search engine tool. You can get an API key [here](https://app.tavily.com/sign-in) or replace with a free tool option (e.g., [duck duck go search](https://python.langchain.com/docs/integrations/tools/ddg)).\n",
    "\n",
    "To see the full langsmith trace, you can s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f52bded-9d23-4826-8bfc-20b0d3a51182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U langgraph langchain_community langchain_openai tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4215f9fb-71ff-4d88-8484-f73174db5592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}=\")\n",
    "\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ReWOO\"\n",
    "_set_if_undefined(\"SERPAPI_API_KEY\")\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "_set_if_undefined(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55239a14-a14d-4117-adb5-07199e1e5e16",
   "metadata": {},
   "source": [
    "**Graph State**: In LangGraph, every node updates a shared graph state. The state is the input to any node whenever it is invoked.\n",
    "\n",
    "Below, we will define a state dict to contain the task, plan, steps, and other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a92c875-c20b-4b7e-9d88-61c62382f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "\n",
    "\n",
    "class ReWOO(TypedDict):\n",
    "    task: str\n",
    "    plan_string: str\n",
    "    steps: List\n",
    "    results: dict\n",
    "    result: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f9181-41c0-4c44-937d-94bd3946a929",
   "metadata": {},
   "source": [
    "## 1. Planner\n",
    "\n",
    "The planner prompts an LLM to generate a plan in the form of a task list. The arguments to each task are strings that may contain special variables (`#E{0-9}+`) that are used for variable subtitution from other task results.\n",
    "\n",
    "\n",
    "![ReWOO workflow](./img/rewoo-paper-workflow.png)\n",
    "\n",
    "Our example agent will have two tools: \n",
    "1. Google - a search engine (in this case Tavily)\n",
    "2. LLM - an LLM call to reason about previous outputs.\n",
    "\n",
    "The LLM tool receives less of the prompt context and so can be more token-efficient than the ReACT paradigm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8836921-c89e-42b6-8c71-27aeaeac5368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\Spectra\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "\n",
    "model = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d136abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "GOOGLE_API_KEY = \"AIzaSyCdJTvBHJqSt1NyC3Km8MgQjgdhz0bLPj0\"  \n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=GOOGLE_API_KEY, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e7faa92-30a1-4942-b3c7-acd3a7bfccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"For the following task, make plans that can solve the problem step by step. For each plan, indicate \\\n",
    "which external tool together with tool input to retrieve evidence. You can store the evidence into a \\\n",
    "variable #E that can be called by later tools. (Plan, #E1, Plan, #E2, Plan, ...)\n",
    "\n",
    "Tools can be one of the following:\n",
    "(1) search db[input]: Worker that searches our text database for products similar to the product in the product description.\n",
    "Useful when you need to find the price of similar products in the text database.\n",
    "The input should be the product description.\n",
    "(2) search internet[input]: Worker that searches product decription from Google for price. \n",
    "Useful when you need to find the price of the product on the internet when given the price description.\n",
    "The input should be a search query.\n",
    "(3) LLM[input]: Worker that uses a language model like yourself to make a decision.\n",
    "\n",
    "For example,\n",
    "Task: what is the estimated, accurate and compact price range of bose ultra wireless noise cancelling headphones?\n",
    "Plan: search db for similar products. #E1 = search db[bose ultra wireless noise cancelling headphones]\n",
    "Plan: search internet for similar products. #E2 = search internet[bose ultra wireless noise cancelling headphones]\n",
    "Plan: get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E3 = LLM[get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E1, #E2]\n",
    "\n",
    "\n",
    "Begin! \n",
    "Describe your plans with rich details. Each Plan should be followed by only one #E.\n",
    "\n",
    "Task: {task}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72b4ab0f-7215-4f4b-9407-0ebad8b13b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"what is the estimated, accurate and compact price range of WorkProÂ® 12000 Series Ergonomic Mesh/Fabric Mid-Back Chair, Black/Black, BIFMA Compliant?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56ecb45b-ea76-4303-a4f3-51406fe8312a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(prompt.format(task=task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a733caa-d75b-422c-93aa-6ad913c995f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plan: search db for similar products. #E1 = search db[WorkProÂ® 12000 Series Ergonomic Mesh/Fabric Mid-Back Chair, Black/Black, BIFMA Compliant]\n",
      "Plan: search internet for similar products. #E2 = search internet[WorkProÂ® 12000 Series Ergonomic Mesh/Fabric Mid-Back Chair, Black/Black, BIFMA Compliant]\n",
      "Plan: get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E3 = LLM[#E1 , #E2 ]\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37166985-5bec-4615-bd40-54d16fd7b4ea",
   "metadata": {},
   "source": [
    "#### Planner Node\n",
    "\n",
    "To connect the planner to our graph, we will create a `get_plan` node that accepts the `ReWOO` state and returns with a state update for the\n",
    "`steps` and `plan_string` fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9f042b6-90d8-430f-abf3-04ad2bb047c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Regex to match expressions of the form E#... = ...[...]\n",
    "regex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\n",
    "prompt_template = ChatPromptTemplate.from_messages([(\"user\", prompt)])\n",
    "planner = prompt_template | model\n",
    "\n",
    "\n",
    "def get_plan(state: ReWOO):\n",
    "    task = state[\"task\"]\n",
    "    result = planner.invoke({\"task\": task})\n",
    "    # Find all matches in the sample text\n",
    "    matches = re.findall(regex_pattern, result.content)\n",
    "    return {\"steps\": matches, \"plan_string\": result.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97942f-27d3-4761-b6cc-6614dbb90c77",
   "metadata": {},
   "source": [
    "## 2. Executor\n",
    "\n",
    "The executor receives the plan and executes the tools in sequence.\n",
    "\n",
    "Below, instantiate the search engine and define the toole execution node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3412cfc4-6796-4295-aea4-7eeb304e10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SearchApiAPIWrapper, SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb56187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify variables\n",
    "from langchain_experimental.open_clip import OpenCLIPEmbeddings\n",
    "\n",
    "model_name = \"ViT-B-16\"\n",
    "checkpoint = \"openai\"\n",
    "embedding_model= OpenCLIPEmbeddings(model_name=model_name, checkpoint=checkpoint)\n",
    "db_dir = \"db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6547c4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "text_db = Chroma(persist_directory=db_dir, embedding_function=embedding_model, collection_name=\"text-collection\")\n",
    "text_retriever = text_db.as_retriever()\n",
    "tool_retrieve_from_text_db = create_retriever_tool(\n",
    "    text_retriever,\n",
    "    'search text db',\n",
    "    'Query a retriever for product price using its product description.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa96fbac-28bc-4afe-ae35-ddb3383d1147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_current_task(state: ReWOO):\n",
    "    if state[\"results\"] is None:\n",
    "        return 1\n",
    "    if len(state[\"results\"]) == len(state[\"steps\"]):\n",
    "        return None\n",
    "    else:\n",
    "        return len(state[\"results\"]) + 1\n",
    "\n",
    "\n",
    "def tool_execution(state: ReWOO):\n",
    "    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n",
    "    _step = _get_current_task(state)\n",
    "    _, step_name, tool, tool_input = state[\"steps\"][_step - 1]\n",
    "    _results = state[\"results\"] or {}\n",
    "    for k, v in _results.items():\n",
    "        tool_input = tool_input.replace(k, v)\n",
    "    if tool == \"search db\":\n",
    "        result = tool_retrieve_from_text_db.invoke(tool_input)\n",
    "    if tool == \"search internet\":\n",
    "        result = search.invoke(tool_input)\n",
    "    elif tool == \"LLM\":\n",
    "        result = model.invoke(tool_input)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    _results[step_name] = str(result)\n",
    "    return {\"results\": _results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e20b31-d721-470d-94d2-db0c177fae75",
   "metadata": {},
   "source": [
    "## 3. Solver\n",
    "\n",
    "The solver receives the full plan and generates the final response based on the responses of the tool calls from the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a4d9851-8590-42be-8c53-9969ebff85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_prompt = \"\"\"Solve the following task or problem where you are to predict the price range of a product. To solve the problem, we have made step-by-step Plan and \\\n",
    "retrieved corresponding Evidence to each Plan. Use them with caution since long evidence might \\\n",
    "contain irrelevant information.\n",
    "\n",
    "{plan}\n",
    "\n",
    "Now solve the question or task according to provided Evidence above. Respond with the answer\n",
    "directly with no extra words.\n",
    "\n",
    "Task: {task}\n",
    "Response:\"\"\"\n",
    "\n",
    "\n",
    "def solve(state: ReWOO):\n",
    "    plan = \"\"\n",
    "    for _plan, step_name, tool, tool_input in state[\"steps\"]:\n",
    "        _results = state[\"results\"] or {}\n",
    "        for k, v in _results.items():\n",
    "            tool_input = tool_input.replace(k, v)\n",
    "            step_name = step_name.replace(k, v)\n",
    "        plan += f\"Plan: {_plan}\\n{step_name} = {tool}[{tool_input}]\"\n",
    "    prompt = solve_prompt.format(plan=plan, task=state[\"task\"])\n",
    "    result = model.invoke(prompt)\n",
    "    return {\"result\": result.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce26c3f-6ced-4a91-a9f2-d0bc235e4010",
   "metadata": {},
   "source": [
    "## 4. Define Graph\n",
    "\n",
    "Our graph defines the workflow. Each of the planner, tool executor, and solver modules are added as nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73b235d7-fa83-4e84-9f2e-2908f16deb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _route(state):\n",
    "    _step = _get_current_task(state)\n",
    "    if _step is None:\n",
    "        # We have executed all tasks\n",
    "        return \"solve\"\n",
    "    else:\n",
    "        # We are still executing tasks, loop back to the \"tool\" node\n",
    "        return \"tool\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cf173aa1-ce31-4dca-8111-30c91e209652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "graph = StateGraph(ReWOO)\n",
    "graph.add_node(\"plan\", get_plan)\n",
    "graph.add_node(\"tool\", tool_execution)\n",
    "graph.add_node(\"solve\", solve)\n",
    "graph.add_edge(\"plan\", \"tool\")\n",
    "graph.add_edge(\"solve\", END)\n",
    "graph.add_conditional_edges(\"tool\", _route)\n",
    "graph.set_entry_point(\"plan\")\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "700c8812",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"what is the estimated, accurate and compact price range of Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "badaca52-5d55-433f-8770-1bd50c10bf7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'plan': {'steps': [('get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices ', '#E3', 'LLM', 'get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E1, #E2')], 'plan_string': 'Plan: search db for similar products. #E1 = search db[Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz]\\nPlan: search internet for similar products. #E2 = search internet[Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz]\\nPlan: get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E3 = LLM[get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E1, #E2]'}}\n",
      "---\n",
      "{'tool': {'results': {'#E3': \"content='**Most Similar Products:**\\\\n\\\\n* Product A\\\\n* Product B\\\\n* Product C\\\\n* Product D\\\\n\\\\n**Products with No Similarity:**\\\\n\\\\n* Product E\\\\n* Product F\\\\n\\\\n**Prices of Most Similar Products:**\\\\n\\\\n* Product A: $10\\\\n* Product B: $12\\\\n* Product C: $15\\\\n* Product D: $18'\"}}}\n",
      "---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:langchain_google_genai.chat_models:Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solve': {'result': '$10-$18'}}\n",
      "---\n",
      "{'__end__': {'task': 'what is the estimated, accurate and compact price range of Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz?', 'plan_string': 'Plan: search db for similar products. #E1 = search db[Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz]\\nPlan: search internet for similar products. #E2 = search internet[Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz]\\nPlan: get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E3 = LLM[get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E1, #E2]', 'steps': [('get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices ', '#E3', 'LLM', 'get the most similar products and drop any that has no similarity. Then get the prices of the most similar prices #E1, #E2')], 'results': {'#E3': \"content='**Most Similar Products:**\\\\n\\\\n* Product A\\\\n* Product B\\\\n* Product C\\\\n* Product D\\\\n\\\\n**Products with No Similarity:**\\\\n\\\\n* Product E\\\\n* Product F\\\\n\\\\n**Prices of Most Similar Products:**\\\\n\\\\n* Product A: $10\\\\n* Product B: $12\\\\n* Product C: $15\\\\n* Product D: $18'\"}, 'result': '$10-$18'}}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for s in app.stream({\"task\": task}):\n",
    "    print(s)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70e5aa0f-4d8b-4f65-817a-1c4ebf07d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not mention anything about the price range of Dior Sauvage for Men, Eau de Parfum Spray, 6.80 Fl Oz, so I cannot extract the requested data from the provided context.\n"
     ]
    }
   ],
   "source": [
    "# Print out the final result\n",
    "print(s[END][\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842954d7-0de0-4876-be63-46b4e14157b0",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations on implementing ReWOO! Before you leave, I'll leave you with a couple limitations of the current implementation from the paper:\n",
    "\n",
    "1. If little context of the environment is available, the planner will be ineffective in its tool use. This can typically be ameliorated through few-shot prompting and/or fine-tuning.\n",
    "2. The tasks are still executed in sequence, meaning the total execution time is impacted by _every_ tool call, not just he longest-running in a given step."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
